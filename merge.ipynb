{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851e6e7e",
   "metadata": {},
   "source": [
    "## 批量为招聘数据匹配上市公司股票代码（Polars）\n",
    "- 使用天眼查桥接表（`原文件导入名称` → `系统匹配企业名称`）对齐名称。\n",
    "- 使用上市公司信息 JSON（如 `STK_LISTEDCOINFOANL.json`）获取（中文全称 → 股票代码）。\n",
    "- 规范化公司名称（去除中英文括号及其中内容、trim 空白）。\n",
    "- 对 `batch_1.parquet` 到 `batch_5.parquet` 逐个处理，输出 `_with_code.parquet`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f639adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.normalize_company_name(name: str | None) -> str | None>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"D:/BaiduNetdiskDownload/招聘数据/合并上市公司\")\n",
    "\n",
    "# 规范化：去除中英文括号，并去除两端空白、全角空格\n",
    "PAREN_PATTERN = re.compile(r\"[（()）]\")\n",
    "FULLWIDTH_SPACE = \"\\u3000\"\n",
    "\n",
    "def normalize_company_name(name: str | None) -> str | None:\n",
    "    if name is None:\n",
    "        return None\n",
    "    s = str(name).strip().replace(FULLWIDTH_SPACE, \" \")\n",
    "    if not s:\n",
    "        return s\n",
    "    s = PAREN_PATTERN.sub(\"\", s)\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "normalize_company_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185e8595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['南京银行股份有限公司上海分行', '深圳A科技有限公司集团', '北京XX公司', None, '阿里巴巴中国有限公司杭州滨江']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试规范化\n",
    "samples = [\n",
    "    \"南京银行股份有限公司(上海分行)\",\n",
    "    \"深圳A科技有限公司（集团）\",\n",
    "    \"  北京XX公司  \",\n",
    "    None,\n",
    "    \"阿里巴巴(中国)有限公司（杭州滨江）\",\n",
    "]\n",
    "[normalize_company_name(s) for s in samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a0ad2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8094, 9348)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建上市公司（中文全称 → 股票代码）映射\n",
    "# STK_LISTEDCOINFOANL.json 可能为 JSON 行或数组，使用惰性读取\n",
    "\n",
    "import ijson\n",
    "\n",
    "listed_name_to_code: dict[str, str] = {}\n",
    "listed_short_to_code: dict[str, str] = {}\n",
    "\n",
    "stk_json_path = BASE / \"STK_LISTEDCOINFOANL.json\"\n",
    "with open(stk_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    try:\n",
    "        # 先尝试读取整个文件作为JSON\n",
    "        content = f.read().strip()\n",
    "        \n",
    "        # 检查是否为JSONL格式（每行一个JSON对象）\n",
    "        if '\\n' in content and not content.startswith('['):\n",
    "            # JSONL格式处理\n",
    "            for line in content.split('\\n'):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                    symbol = obj.get(\"Symbol\") or obj.get(\"股票代码\")\n",
    "                    full_name = obj.get(\"FullName\") or obj.get(\"中文全称\")\n",
    "                    short_name = obj.get(\"ShortName\") or obj.get(\"股票简称\")\n",
    "                    if symbol and full_name:\n",
    "                        norm = normalize_company_name(full_name)\n",
    "                        if norm:\n",
    "                            listed_name_to_code.setdefault(norm, str(symbol))\n",
    "                    if symbol and short_name:\n",
    "                        listed_short_to_code.setdefault(str(short_name).strip(), str(symbol))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        else:\n",
    "            # 标准JSON格式处理\n",
    "            obj = json.loads(content)\n",
    "            if isinstance(obj, list):\n",
    "                for it in obj:\n",
    "                    symbol = it.get(\"Symbol\") or it.get(\"股票代码\")\n",
    "                    full_name = it.get(\"FullName\") or it.get(\"中文全称\")\n",
    "                    short_name = it.get(\"ShortName\") or it.get(\"股票简称\")\n",
    "                    if symbol and full_name:\n",
    "                        norm = normalize_company_name(full_name)\n",
    "                        if norm:\n",
    "                            listed_name_to_code.setdefault(norm, str(symbol))\n",
    "                    if symbol and short_name:\n",
    "                        listed_short_to_code.setdefault(str(short_name).strip(), str(symbol))\n",
    "            elif isinstance(obj, dict):\n",
    "                # 如果是字典，尝试处理其值\n",
    "                for key, it in obj.items():\n",
    "                    if isinstance(it, dict):\n",
    "                        symbol = it.get(\"Symbol\") or it.get(\"股票代码\")\n",
    "                        full_name = it.get(\"FullName\") or it.get(\"中文全称\")\n",
    "                        short_name = it.get(\"ShortName\") or it.get(\"股票简称\")\n",
    "                        if symbol and full_name:\n",
    "                            norm = normalize_company_name(full_name)\n",
    "                            if norm:\n",
    "                                listed_name_to_code.setdefault(norm, str(symbol))\n",
    "                        if symbol and short_name:\n",
    "                            listed_short_to_code.setdefault(str(short_name).strip(), str(symbol))\n",
    "                    elif isinstance(it, list):\n",
    "                        # 如果值是列表，处理列表中的每个元素\n",
    "                        for item in it:\n",
    "                            if isinstance(item, dict):\n",
    "                                symbol = item.get(\"Symbol\") or item.get(\"股票代码\")\n",
    "                                full_name = item.get(\"FullName\") or item.get(\"中文全称\")\n",
    "                                short_name = item.get(\"ShortName\") or item.get(\"股票简称\")\n",
    "                                if symbol and full_name:\n",
    "                                    norm = normalize_company_name(full_name)\n",
    "                                    if norm:\n",
    "                                        listed_name_to_code.setdefault(norm, str(symbol))\n",
    "                                if symbol and short_name:\n",
    "                                    listed_short_to_code.setdefault(str(short_name).strip(), str(symbol))\n",
    "                \n",
    "    except (json.JSONDecodeError, UnicodeDecodeError) as e:\n",
    "        print(f\"Error reading {stk_json_path}: {e}\")\n",
    "        print(\"Please check the file format and encoding\")\n",
    "\n",
    "len(listed_name_to_code), len(listed_short_to_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3895b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257849"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建子公司 → 上市公司股票代码映射\n",
    "# 读取 FN_Fn061.json / FN_Fn0611.json，字段：Stkcd（证券代码）、FN_Fn06101（子公司名称）\n",
    "\n",
    "subsidiary_to_code: dict[str, str] = {}\n",
    "\n",
    "for fname in [\"FN_Fn061.json\", \"FN_Fn0611.json\"]:\n",
    "    fpath = BASE / fname\n",
    "    if not fpath.exists():\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 先尝试读取文件内容\n",
    "        with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read().strip()\n",
    "        \n",
    "        if not content:\n",
    "            continue\n",
    "            \n",
    "        # 尝试解析为标准JSON\n",
    "        try:\n",
    "            # 标准JSON格式处理\n",
    "            obj = json.loads(content)\n",
    "            if isinstance(obj, list):\n",
    "                for it in obj:\n",
    "                    code = it.get(\"Stkcd\") or it.get(\"证券代码\")\n",
    "                    sub_name = it.get(\"FN_Fn06101\") or it.get(\"子公司名称\")\n",
    "                    if not sub_name or not code:\n",
    "                        continue\n",
    "                    norm = normalize_company_name(sub_name)\n",
    "                    if norm:\n",
    "                        subsidiary_to_code.setdefault(norm, str(code))\n",
    "            elif isinstance(obj, dict):\n",
    "                # 如果是字典，尝试处理其值\n",
    "                for key, it in obj.items():\n",
    "                    if isinstance(it, dict):\n",
    "                        code = it.get(\"Stkcd\") or it.get(\"证券代码\")\n",
    "                        sub_name = it.get(\"FN_Fn06101\") or it.get(\"子公司名称\")\n",
    "                        if not sub_name or not code:\n",
    "                            continue\n",
    "                        norm = normalize_company_name(sub_name)\n",
    "                        if norm:\n",
    "                            subsidiary_to_code.setdefault(norm, str(code))\n",
    "                    elif isinstance(it, list):\n",
    "                        # 如果值是列表，处理列表中的每个元素\n",
    "                        for item in it:\n",
    "                            if isinstance(item, dict):\n",
    "                                code = item.get(\"Stkcd\") or item.get(\"证券代码\")\n",
    "                                sub_name = item.get(\"FN_Fn06101\") or item.get(\"子公司名称\")\n",
    "                                if not sub_name or not code:\n",
    "                                    continue\n",
    "                                norm = normalize_company_name(sub_name)\n",
    "                                if norm:\n",
    "                                    subsidiary_to_code.setdefault(norm, str(code))\n",
    "                \n",
    "        except json.JSONDecodeError:\n",
    "            # 如果标准JSON解析失败，尝试逐行解析\n",
    "            lines = content.strip().split('\\n')\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                    code = obj.get(\"Stkcd\") or obj.get(\"证券代码\")\n",
    "                    sub_name = obj.get(\"FN_Fn06101\") or obj.get(\"子公司名称\")\n",
    "                    if not sub_name or not code:\n",
    "                        continue\n",
    "                    norm = normalize_company_name(sub_name)\n",
    "                    if norm:\n",
    "                        subsidiary_to_code.setdefault(norm, str(code))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "                \n",
    "    except (json.JSONDecodeError, UnicodeDecodeError) as e:\n",
    "        print(f\"Error reading {fpath}: {e}\")\n",
    "        print(\"Please check the file format and encoding\")\n",
    "\n",
    "len(subsidiary_to_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc4de77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name_raw</th><th>name_std</th><th>name_raw_norm</th><th>name_std_norm</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;广州权嚎门投资管理有限公司&quot;</td><td>&quot;广州权嚎门投资管理有限公司&quot;</td><td>&quot;广州权嚎门投资管理有限公司&quot;</td><td>&quot;广州权嚎门投资管理有限公司&quot;</td></tr><tr><td>&quot;深圳澳源达国际物流有限公司&quot;</td><td>&quot;深圳澳源达国际物流有限公司&quot;</td><td>&quot;深圳澳源达国际物流有限公司&quot;</td><td>&quot;深圳澳源达国际物流有限公司&quot;</td></tr><tr><td>&quot;厦门市望众达贸易有限公司&quot;</td><td>&quot;厦门市望众达贸易有限公司&quot;</td><td>&quot;厦门市望众达贸易有限公司&quot;</td><td>&quot;厦门市望众达贸易有限公司&quot;</td></tr><tr><td>&quot;合肥趁坦代驾服务有限公司&quot;</td><td>&quot;合肥趁坦代驾服务有限公司&quot;</td><td>&quot;合肥趁坦代驾服务有限公司&quot;</td><td>&quot;合肥趁坦代驾服务有限公司&quot;</td></tr><tr><td>&quot;二道区爱儿推推拿馆&quot;</td><td>&quot;二道区爱儿推推拿馆&quot;</td><td>&quot;二道区爱儿推推拿馆&quot;</td><td>&quot;二道区爱儿推推拿馆&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌────────────────────────┬────────────────────────┬────────────────────────┬───────────────────────┐\n",
       "│ name_raw               ┆ name_std               ┆ name_raw_norm          ┆ name_std_norm         │\n",
       "│ ---                    ┆ ---                    ┆ ---                    ┆ ---                   │\n",
       "│ str                    ┆ str                    ┆ str                    ┆ str                   │\n",
       "╞════════════════════════╪════════════════════════╪════════════════════════╪═══════════════════════╡\n",
       "│ 广州权嚎门投资管理有限 ┆ 广州权嚎门投资管理有限 ┆ 广州权嚎门投资管理有限 ┆ 广州权嚎门投资管理有  │\n",
       "│ 公司                   ┆ 公司                   ┆ 公司                   ┆ 限公司                │\n",
       "│ 深圳澳源达国际物流有限 ┆ 深圳澳源达国际物流有限 ┆ 深圳澳源达国际物流有限 ┆ 深圳澳源达国际物流有  │\n",
       "│ 公司                   ┆ 公司                   ┆ 公司                   ┆ 限公司                │\n",
       "│ 厦门市望众达贸易有限公 ┆ 厦门市望众达贸易有限公 ┆ 厦门市望众达贸易有限公 ┆ 厦门市望众达贸易有限  │\n",
       "│ 司                     ┆ 司                     ┆ 司                     ┆ 公司                  │\n",
       "│ 合肥趁坦代驾服务有限公 ┆ 合肥趁坦代驾服务有限公 ┆ 合肥趁坦代驾服务有限公 ┆ 合肥趁坦代驾服务有限  │\n",
       "│ 司                     ┆ 司                     ┆ 司                     ┆ 公司                  │\n",
       "│ 二道区爱儿推推拿馆     ┆ 二道区爱儿推推拿馆     ┆ 二道区爱儿推推拿馆     ┆ 二道区爱儿推推拿馆    │\n",
       "└────────────────────────┴────────────────────────┴────────────────────────┴───────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建天眼查桥接表：原文件导入名称（≈ batch 的公司名称） → 系统匹配企业名称（对齐上市库的名称）\n",
    "# 这个桥接表的作用是将batch数据中的非标准公司名称映射到标准的企业名称\n",
    "\n",
    "bridge_path = BASE / \"tianyancha.parquet\"\n",
    "bridge_df = pl.read_parquet(bridge_path)\n",
    "\n",
    "# 自动识别桥接表中的关键字段名称，因为不同数据源的字段名可能不同\n",
    "# name_src_col: 对应batch数据中的原始公司名称字段\n",
    "# name_std_col: 对应标准化后的企业名称字段\n",
    "cols = {c: c for c in bridge_df.columns}\n",
    "name_src_col = next((c for c in bridge_df.columns if c in (\"原文件导入名称\", \"原始公司名称\", \"公司名称\", \"name_raw\")), None)\n",
    "name_std_col = next((c for c in bridge_df.columns if c in (\"系统匹配企业名称\", \"标准企业名称\", \"匹配企业名称\", \"name_std\")), None)\n",
    "\n",
    "# 如果找不到必要的字段，抛出错误\n",
    "if name_src_col is None or name_std_col is None:\n",
    "    raise ValueError(f\"桥接表缺少必要字段，现有列：{bridge_df.columns}\")\n",
    "\n",
    "# 处理桥接表数据：\n",
    "# 1. 选择并重命名关键字段为统一的名称\n",
    "# 2. 对原始名称和标准名称都进行规范化处理（去除括号等）\n",
    "# 3. 去重，保留第一条记录（基于规范化后的原始名称）\n",
    "bridge_df = bridge_df.select([\n",
    "    pl.col(name_src_col).alias(\"name_raw\"),        # 原始公司名称\n",
    "    pl.col(name_std_col).alias(\"name_std\")         # 标准企业名称\n",
    "]).with_columns([\n",
    "    # 对原始名称进行规范化处理\n",
    "    pl.col(\"name_raw\").map_elements(normalize_company_name, return_dtype=pl.Utf8).alias(\"name_raw_norm\"),\n",
    "    # 对标准名称进行规范化处理\n",
    "    pl.col(\"name_std\").map_elements(normalize_company_name, return_dtype=pl.Utf8).alias(\"name_std_norm\")\n",
    "]).unique(subset=[\"name_raw_norm\"], keep=\"first\")  # 基于规范化的原始名称去重\n",
    "\n",
    "bridge_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9cfe1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(shape: (5, 2)\n",
       " ┌────────────────────────────────┬────────────┐\n",
       " │ listed_full_norm               ┆ stock_code │\n",
       " │ ---                            ┆ ---        │\n",
       " │ str                            ┆ str        │\n",
       " ╞════════════════════════════════╪════════════╡\n",
       " │ 深圳发展银行股份有限公司       ┆ 000001     │\n",
       " │ 平安银行股份有限公司           ┆ 000001     │\n",
       " │ 万科企业股份有限公司           ┆ 000002     │\n",
       " │ 金田实业集团股份有限公司       ┆ 000003     │\n",
       " │ 深圳市蛇口安达实业股份有限公司 ┆ 000004     │\n",
       " └────────────────────────────────┴────────────┘,\n",
       " shape: (5, 2)\n",
       " ┌──────────────┬────────────┐\n",
       " │ listed_short ┆ stock_code │\n",
       " │ ---          ┆ ---        │\n",
       " │ str          ┆ str        │\n",
       " ╞══════════════╪════════════╡\n",
       " │ 深发展A      ┆ 000001     │\n",
       " │ 平安银行     ┆ 000001     │\n",
       " │ 深万科A      ┆ 000002     │\n",
       " │ 万科A        ┆ 000002     │\n",
       " │ G 万科A      ┆ 000002     │\n",
       " └──────────────┴────────────┘,\n",
       " shape: (5, 2)\n",
       " ┌────────────────────────────┬────────────┐\n",
       " │ subsidiary_norm            ┆ stock_code │\n",
       " │ ---                        ┆ ---        │\n",
       " │ str                        ┆ str        │\n",
       " ╞════════════════════════════╪════════════╡\n",
       " │ 深圳市元盛实业有限公司     ┆ 000001     │\n",
       " │ 深圳市深发投资发展有限公司 ┆ 000001     │\n",
       " │ 上海元盛房地产有限公司     ┆ 000001     │\n",
       " │ 大连元盛房屋开发有限公司   ┆ 000001     │\n",
       " │ 上海银涛房地产开发有限公司 ┆ 000001     │\n",
       " └────────────────────────────┴────────────┘)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成用于连接的上市公司和子公司 DataFrame（便于 Polars join）\n",
    "\n",
    "listed_df = pl.DataFrame({\n",
    "    \"listed_full_norm\": list(listed_name_to_code.keys()),\n",
    "    \"stock_code\": list(listed_name_to_code.values()),\n",
    "})\n",
    "\n",
    "listed_short_df = pl.DataFrame({\n",
    "    \"listed_short\": list(listed_short_to_code.keys()),\n",
    "    \"stock_code\": list(listed_short_to_code.values()),\n",
    "})\n",
    "\n",
    "subsidiary_df = pl.DataFrame({\n",
    "    \"subsidiary_norm\": list(subsidiary_to_code.keys()),\n",
    "    \"stock_code\": list(subsidiary_to_code.values()),\n",
    "})\n",
    "\n",
    "listed_df.head(), listed_short_df.head(), subsidiary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7372bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理batch文件:  20%|██        | 1/5 [01:27<05:49, 87.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: D:\\BaiduNetdiskDownload\\招聘数据\\合并上市公司\\batch_1_with_code.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理batch文件:  40%|████      | 2/5 [03:04<04:39, 93.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: D:\\BaiduNetdiskDownload\\招聘数据\\合并上市公司\\batch_2_with_code.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理batch文件:  60%|██████    | 3/5 [05:06<03:32, 106.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: D:\\BaiduNetdiskDownload\\招聘数据\\合并上市公司\\batch_3_with_code.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理batch文件:  80%|████████  | 4/5 [06:43<01:42, 102.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: D:\\BaiduNetdiskDownload\\招聘数据\\合并上市公司\\batch_4_with_code.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理batch文件: 100%|██████████| 5/5 [07:14<00:00, 86.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: D:\\BaiduNetdiskDownload\\招聘数据\\合并上市公司\\batch_5_with_code.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 处理 batch_* 数据：\n",
    "# 1) 规范化 batch 的公司名称\n",
    "# 2) 与桥接表用 name_raw_norm → name_std_norm 对齐\n",
    "# 3) 优先用标准全称去上市公司表匹配，其次用简称匹配，再用子公司匹配\n",
    "# 4) 输出带 stock_code 的 parquet\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_files = [BASE / f\"batch_{i}.parquet\" for i in range(1, 6)]\n",
    "\n",
    "for fpath in tqdm(batch_files, desc=\"处理batch文件\"):\n",
    "    if not fpath.exists():\n",
    "        continue\n",
    "    df = pl.read_parquet(fpath)\n",
    "\n",
    "    # 猜测 batch 公司名字段\n",
    "    batch_name_col = next((c for c in df.columns if c in (\"公司名称\", \"企业名称\", \"name\", \"company_name\")), None)\n",
    "    if batch_name_col is None:\n",
    "        raise ValueError(f\"{fpath.name} 缺少公司名称字段，现有列：{df.columns}\")\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(batch_name_col).map_elements(normalize_company_name, return_dtype=pl.Utf8).alias(\"name_raw_norm\")\n",
    "    ])\n",
    "\n",
    "    # 与桥接表对齐，得到标准名称\n",
    "    df = df.join(\n",
    "        bridge_df.select([\"name_raw_norm\", \"name_std_norm\"]),\n",
    "        on=\"name_raw_norm\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # 用标准全称匹配上市公司\n",
    "    df = df.join(\n",
    "        listed_df,\n",
    "        left_on=\"name_std_norm\",\n",
    "        right_on=\"listed_full_norm\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_listed_full\",\n",
    "    )\n",
    "\n",
    "    # 若未命中，尝试用标准名称（可能为简称）去短名表匹配\n",
    "    df = df.with_columns([\n",
    "        pl.when(pl.col(\"stock_code\").is_null())\n",
    "          .then(pl.col(\"name_std_norm\"))\n",
    "          .otherwise(None)\n",
    "          .alias(\"tmp_short\")\n",
    "    ])\n",
    "    df = df.join(\n",
    "        listed_short_df.rename({\"stock_code\": \"stock_code_short\"}),\n",
    "        left_on=\"tmp_short\",\n",
    "        right_on=\"listed_short\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # 若还未命中，尝试子公司表（用原始规范化名称，以覆盖\"公司名称\"为子公司名的情形）\n",
    "    df = df.join(\n",
    "        subsidiary_df.rename({\"stock_code\": \"stock_code_sub\"}),\n",
    "        left_on=\"name_raw_norm\",\n",
    "        right_on=\"subsidiary_norm\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # 汇总优先级：全称匹配 > 简称匹配 > 子公司匹配\n",
    "    df = df.with_columns([\n",
    "        pl.coalesce([pl.col(\"stock_code\"), pl.col(\"stock_code_short\"), pl.col(\"stock_code_sub\")]).alias(\"stock_code_final\")\n",
    "    ]).drop([c for c in [\"tmp_short\", \"listed_full_norm\", \"listed_short\", \"subsidiary_norm\", \"stock_code\", \"stock_code_short\", \"stock_code_sub\"] if c in df.columns])\n",
    "\n",
    "    out_path = fpath.with_name(fpath.stem + \"_with_code.parquet\")\n",
    "    df.write_parquet(out_path)\n",
    "    print(f\"wrote: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0365e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: batch_1_matched.parquet, rows: 898915\n",
      "wrote: batch_2_matched.parquet, rows: 931774\n",
      "wrote: batch_3_matched.parquet, rows: 1076243\n",
      "wrote: batch_4_matched.parquet, rows: 1407198\n",
      "wrote: batch_5_matched.parquet, rows: 714201\n",
      "wrote: matched_all.parquet\n"
     ]
    }
   ],
   "source": [
    "# 过滤出能匹配到股票代码的记录，分别与汇总保存\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "BASE = Path(\".\")  # 定义BASE路径\n",
    "\n",
    "matched_paths = []\n",
    "for i in range(1, 6):\n",
    "    in_path = BASE / f\"batch_{i}_with_code.parquet\"\n",
    "    if not in_path.exists():\n",
    "        continue\n",
    "    df = pl.read_parquet(in_path)\n",
    "    if \"stock_code_final\" not in df.columns:\n",
    "        # 兼容如果用户直接在原始 batch 上执行此单元格\n",
    "        if \"stock_code\" in df.columns:\n",
    "            code_col = \"stock_code\"\n",
    "        else:\n",
    "            raise ValueError(f\"{in_path.name} 缺少 stock_code_final/stock_code 列\")\n",
    "    else:\n",
    "        code_col = \"stock_code_final\"\n",
    "\n",
    "    df_matched = df.filter(pl.col(code_col).is_not_null())\n",
    "    out_path = BASE / f\"batch_{i}_matched.parquet\"\n",
    "    df_matched.write_parquet(out_path)\n",
    "    matched_paths.append(out_path)\n",
    "    print(f\"wrote: {out_path}, rows: {df_matched.height}\")\n",
    "\n",
    "# 汇总输出（若存在多个文件）\n",
    "if matched_paths:\n",
    "    dfs = [pl.read_parquet(p) for p in matched_paths]\n",
    "    pl.concat(dfs, how=\"vertical_relaxed\").write_parquet(BASE / \"matched_all.parquet\")\n",
    "    print(\"wrote: matched_all.parquet\")\n",
    "else:\n",
    "    print(\"未发现 matched 数据文件可汇总\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
