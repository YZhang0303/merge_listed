{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('matched_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def clean_description(text: object) -> str:\n",
    "    \"\"\"Clean raw HTML-ish job description text.\n",
    "\n",
    "    - Trim whitespace/newlines at both ends\n",
    "    - Replace \\xa0 and &nbsp; with spaces\n",
    "    - Remove common HTML tags; keep line breaks where sensible\n",
    "    - Collapse repeated spaces/newlines\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    if not isinstance(text, str):\n",
    "        try:\n",
    "            text = str(text)\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    s = text.replace(\"\\xa0\", \" \")\n",
    "    s = s.replace(\"&nbsp;\", \" \")\n",
    "    # Decode common HTML entities (e.g., &amp;, &lt;, &gt;)\n",
    "    s = html.unescape(s)\n",
    "\n",
    "    # Preserve structural breaks for <br> and <p>, then strip remaining tags\n",
    "    s = re.sub(r\"<br\\s*/?>\", \"\\n\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"</?p[^>]*>\", \"\\n\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"</?(div|span|ul|ol|li|strong|em|font)[^>]*>\", \"\\n\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)  # any remaining tags\n",
    "\n",
    "    # Normalize whitespace\n",
    "    s = s.replace(\"\\r\", \"\\n\")\n",
    "    s = re.sub(r\"\\t+\", \" \", s)\n",
    "    s = re.sub(r\"\\n+\", \"\\n\", s)\n",
    "    s = re.sub(r\"[ \\u3000]{2,}\", \" \", s)\n",
    "\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def extract_responsibilities(text: object) -> List[str]:\n",
    "    \"\"\"Extract ordered list items (n. or n、) for job responsibilities.\n",
    "\n",
    "    Rules:\n",
    "    - Find the first ordered list that starts with a numeric marker like \"1.\" or \"1、\".\n",
    "    - Collect subsequent items until a new ordered list restart is detected (the next \"1.\"/\"1、\").\n",
    "    - Ignore everything after the restart.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return []\n",
    "    if not isinstance(text, str):\n",
    "        try:\n",
    "            text = str(text)\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "    content = text\n",
    "\n",
    "    # Match numbers like 1. or 1、 (1-2 digits), not preceded by a digit\n",
    "    marker_pattern = re.compile(r\"(?<!\\d)(\\d{1,2})[\\.、]\\s*\")\n",
    "    matches = list(marker_pattern.finditer(content))\n",
    "    if not matches:\n",
    "        return []\n",
    "\n",
    "    # Find the first occurrence of marker == 1\n",
    "    first_idx = None\n",
    "    for idx, m in enumerate(matches):\n",
    "        if m.group(1) == \"1\":\n",
    "            first_idx = idx\n",
    "            break\n",
    "    if first_idx is None:\n",
    "        return []\n",
    "\n",
    "    items: List[str] = []\n",
    "    for i in range(first_idx, len(matches)):\n",
    "        current = matches[i]\n",
    "        # Stop if a new list restarts at 1 (excluding the very first 1)\n",
    "        if i > first_idx and current.group(1) == \"1\":\n",
    "            break\n",
    "        start_pos = current.end()\n",
    "        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(content)\n",
    "\n",
    "        raw = content[start_pos:end_pos]\n",
    "        # Trim leading bullets/punctuations and trailing sentence punctuation\n",
    "        raw = re.sub(r\"^[：:;；\\-\\s·•]+\", \"\", raw)\n",
    "        cleaned = raw.strip()\n",
    "        if cleaned:\n",
    "            cleaned = re.sub(r\"[；;。\\s]+$\", \"\", cleaned)\n",
    "            items.append(cleaned)\n",
    "\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成用于批量调用的大模型请求 JSONL（200条）#百炼\n",
    "import os, json\n",
    "\n",
    "system_prompt = \"请提取岗位描述信息中的岗位职责，返回Python列表。若岗位描述信息中没有岗位职责，返回none。\"\n",
    "\n",
    "out_dir = os.path.join('.', '中间文件')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, 'batch_responsibilities_200.jsonl')\n",
    "\n",
    "with open(out_path, 'w', encoding='utf-8') as f:\n",
    "    for _, row in df_sample.reset_index().iterrows():\n",
    "        original_idx = int(row['index']) if 'index' in row else _\n",
    "        desc = row.get('岗位描述', '')\n",
    "        user_text = clean_description(desc) if pd.notna(desc) else \"\"\n",
    "        payload = {\n",
    "            \"custom_id\": f\"resp-{original_idx:06d}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"qwen-flash\",\n",
    "                \"temperature\": 0,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_text}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print('写入完成:', out_path)\n",
    "# 预览前两行\n",
    "with open(out_path, 'r', encoding='utf-8') as f:\n",
    "    for _ in range(2):\n",
    "        print(f.readline().rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成用于批量调用的大模型请求 JSONL（200条）#智谱\n",
    "import os, json\n",
    "\n",
    "system_prompt = \"请提取岗位描述信息中的岗位职责或任务，输出{\\\"responsibilities\\\":[\\\"…\\\",\\\"…\\\"]}。若岗位描述信息中没有岗位职责，输出{\\\"responsibilities\\\":[]}。\"\n",
    "\n",
    "out_dir = os.path.join('.', '中间文件')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, 'batch_responsibilities_200_zhipu.jsonl')\n",
    "\n",
    "with open(out_path, 'w', encoding='utf-8') as f:\n",
    "    for _, row in df_sample.reset_index().iterrows():\n",
    "        original_idx = int(row['index']) if 'index' in row else _\n",
    "        desc = row.get('岗位描述', '')\n",
    "        user_text = clean_description(desc) if pd.notna(desc) else \"\"\n",
    "        payload = {\n",
    "            \"custom_id\": f\"resp-{original_idx:06d}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v4/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"glm-4-flash\",\n",
    "                \"temperature\": 0.1,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_text}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print('写入完成:', out_path)\n",
    "# 预览前两行\n",
    "with open(out_path, 'r', encoding='utf-8') as f:\n",
    "    for _ in range(2):\n",
    "        print(f.readline().rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录 custom_id 与原始行号映射，便于回写\n",
    "map_path = os.path.join(out_dir, 'batch_responsibilities_200_map.csv')\n",
    "(\n",
    "    df_sample.reset_index()[['index']]\n",
    "      .rename(columns={'index': 'row_index'})\n",
    "      .assign(custom_id=lambda d: d['row_index'].apply(lambda x: f'resp-{int(x):06d}'))\n",
    "      .to_csv(map_path, index=False, encoding='utf-8')\n",
    ")\n",
    "print('映射写入完成:', map_path)\n",
    "!powershell -NoProfile -Command \"Get-Content -TotalCount 3 -Path \\\"$env:CD\\\\中间文件\\\\batch_responsibilities_200_map.csv\\\" | % {$_}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d88a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析返回的 JSONL\n",
    "ret_path = os.path.join(out_dir, '471b56b6-c1e4-4710-910d-949d98a544d1_1757233593021_success.jsonl')\n",
    "rows = []\n",
    "with open(ret_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        custom_id = obj.get('custom_id')\n",
    "        # 优先从 choices[0].message.content 取内容\n",
    "        content = None\n",
    "        try:\n",
    "            content = obj['response']['body']['choices'][0]['message']['content']\n",
    "        except Exception:\n",
    "            content = None\n",
    "        rows.append({'custom_id': custom_id, 'raw_content': content})\n",
    "\n",
    "import pandas as pd\n",
    "ret_df = pd.DataFrame(rows)\n",
    "ret_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8527f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果归一化：将raw_content解析为Python列表或None\n",
    "from ast import literal_eval\n",
    "\n",
    "def normalize_to_list_or_none(text: object):\n",
    "    if text is None:\n",
    "        return None\n",
    "    if isinstance(text, list):\n",
    "        return text\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    s = text.strip()\n",
    "    # 允许两种常见形式：1) Python 列表字符串 2) JSON 数组字符串\n",
    "    # 优先尝试literal_eval（兼容单引号），失败再尝试json.loads\n",
    "    try:\n",
    "        val = literal_eval(s)\n",
    "        if isinstance(val, list):\n",
    "            return [str(x).strip() for x in val]\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        val = json.loads(s)\n",
    "        if isinstance(val, list):\n",
    "            return [str(x).strip() for x in val]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 有时模型会返回\"none\"、\"null\"等\n",
    "    if s.lower() in {\"none\", \"null\", \"无\", \"没有\"}:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "ret_df['岗位职责_列表'] = ret_df['raw_content'].map(normalize_to_list_or_none)\n",
    "ret_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并回200条样本（通过mapping）\n",
    "map_df = pd.read_csv(os.path.join(out_dir, 'batch_responsibilities_200_map.csv'), encoding='utf-8')\n",
    "merged = (map_df.merge(ret_df[['custom_id','岗位职责_列表']], on='custom_id', how='left')\n",
    "                .merge(df_sample.reset_index()[['index','岗位描述','岗位描述_清洗','岗位职责列表']], left_on='row_index', right_on='index', how='left'))\n",
    "\n",
    "# 新列命名：模型抽取 vs 规则抽取\n",
    "merged = merged.rename(columns={'岗位职责_列表': '岗位职责_模型抽取', '岗位职责列表': '岗位职责_规则抽取'})\n",
    "\n",
    "# 预览成功解析条数\n",
    "print('模型抽取非空条数:', merged['岗位职责_模型抽取'].map(lambda x: isinstance(x, list) and len(x) > 0).sum())\n",
    "print('总条数:', len(merged))\n",
    "merged.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e50228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出预览到 Excel\n",
    "preview_cols = ['row_index', 'custom_id', '岗位描述', '岗位描述_清洗', '岗位职责_规则抽取', '岗位职责_模型抽取']\n",
    "excel_path = os.path.join('.', 'responsibility_preview.xlsx')\n",
    "(\n",
    "    merged[preview_cols]\n",
    "        .sort_values('row_index')\n",
    "        .to_excel(excel_path, index=False)\n",
    ")\n",
    "print('Excel 写入完成:', excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd110946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取每个请求的输入/输出 token 数量到 DataFrame\n",
    "usage_rows = []\n",
    "with open(ret_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        custom_id = obj.get('custom_id')\n",
    "        resp = obj.get('response', {})\n",
    "        status_code = resp.get('status_code')\n",
    "        body = resp.get('body', {}) or {}\n",
    "        usage = body.get('usage', {}) or {}\n",
    "        model = body.get('model')\n",
    "        usage_rows.append({\n",
    "            'custom_id': custom_id,\n",
    "            'status_code': status_code,\n",
    "            'model': model,\n",
    "            'prompt_tokens': usage.get('prompt_tokens'),\n",
    "            'completion_tokens': usage.get('completion_tokens'),\n",
    "            'total_tokens': usage.get('total_tokens')\n",
    "        })\n",
    "\n",
    "usage_df = pd.DataFrame(usage_rows)\n",
    "for col in ['prompt_tokens', 'completion_tokens', 'total_tokens']:\n",
    "    usage_df[col] = pd.to_numeric(usage_df[col], errors='coerce').astype('Int64')\n",
    "\n",
    "print('行数:', len(usage_df))\n",
    "usage_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重写 batch_responsibilities_200.jsonl 为简化schema（仅 custom_id + body），温度=1\n",
    "import os, json\n",
    "\n",
    "# 准备数据与函数（兜底）\n",
    "if 'pd' not in globals():\n",
    "    import pandas as pd\n",
    "if 'df_sample' not in globals():\n",
    "    if 'df' not in globals():\n",
    "        df = pd.read_parquet('matched_all.parquet')\n",
    "    df_sample = df[['岗位描述']].head(200).copy()\n",
    "if 'clean_description' not in globals():\n",
    "    def clean_description(text):\n",
    "        if text is None:\n",
    "            return ''\n",
    "        return str(text).strip()\n",
    "\n",
    "system_prompt = \"请提取岗位描述信息中的岗位职责，返回Python列表。若岗位描述信息中没有岗位职责，返回none。\"\n",
    "\n",
    "out_dir = os.path.join('.', '中间文件')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, 'batch_responsibilities_200_doubao.jsonl')\n",
    "\n",
    "with open(out_path, 'w', encoding='utf-8') as f:\n",
    "    for i, row in df_sample.reset_index().iterrows():\n",
    "        original_idx = int(row['index']) if 'index' in row else i\n",
    "        desc = row.get('岗位描述', '')\n",
    "        user_text = clean_description(desc) if pd.notna(desc) else ''\n",
    "        obj = {\n",
    "            \"custom_id\": f\"resp-{original_idx:06d}\",\n",
    "            \"body\": {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_text}\n",
    "                ],\n",
    "                \"temperature\": 0,\n",
    "                \"thinking \":{\"type\":\"disabled\"}\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print('已重写:', out_path)\n",
    "with open(out_path, 'r', encoding='utf-8') as f:\n",
    "    for _ in range(2):\n",
    "        print(f.readline().rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20490462",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usage_df['prompt_tokens'].sum())\n",
    "print(usage_df['completion_tokens'].sum())\n",
    "comsumption = usage_df['prompt_tokens'].sum()/1000*0.00015/2 + usage_df['completion_tokens'].sum()/1000*0.0015/2\n",
    "print('comsumption:', comsumption)\n",
    "print('estimated total comsumption:', df.shape[0]/200*comsumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_df.sort_values('prompt_tokens', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7870a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全量清洗并按5万条切分导出为智谱JSONL，带进度条\n",
    "import os, json, math\n",
    "\n",
    "# 进度条优先使用 tqdm；若不可用则降级为分片进度打印\n",
    "try:\n",
    "    from tqdm import tqdm  # type: ignore\n",
    "except Exception:  # noqa: BLE001\n",
    "    tqdm = None  # type: ignore\n",
    "\n",
    "# 兜底导入\n",
    "if 'pd' not in globals():\n",
    "    import pandas as pd  # type: ignore\n",
    "\n",
    "# 读取全量数据（若未读取）\n",
    "if 'df' not in globals():\n",
    "    df = pd.read_parquet('matched_all.parquet')\n",
    "\n",
    "# 清洗函数（若之前未定义，则提供兜底版本）\n",
    "if 'clean_description' in globals():\n",
    "    clean_fn = clean_description\n",
    "else:\n",
    "    import re, html\n",
    "    def clean_fn(text: object) -> str:\n",
    "        if text is None:\n",
    "            return ''\n",
    "        if not isinstance(text, str):\n",
    "            try:\n",
    "                text = str(text)\n",
    "            except Exception:  # noqa: BLE001\n",
    "                return ''\n",
    "        s = text.replace('\\xa0', ' ').replace('&nbsp;', ' ')\n",
    "        s = html.unescape(s)\n",
    "        s = re.sub(r\"<br\\s*/?>\", \"\\n\", s, flags=re.IGNORECASE)\n",
    "        s = re.sub(r\"</?p[^>]*>\", \"\\n\", s, flags=re.IGNORECASE)\n",
    "        s = re.sub(r\"</?(div|span|ul|ol|li|strong|em|font)[^>]*>\", \"\\n\", s, flags=re.IGNORECASE)\n",
    "        s = re.sub(r\"<[^>]+>\", \" \", s)\n",
    "        s = s.replace(\"\\r\", \"\\n\")\n",
    "        s = re.sub(r\"\\t+\", \" \", s)\n",
    "        s = re.sub(r\"\\n+\", \"\\n\", s)\n",
    "        s = re.sub(r\"[ \\u3000]{2,}\", \" \", s)\n",
    "        return s.strip()\n",
    "\n",
    "# 生成清洗列\n",
    "df_all = df.copy()\n",
    "df_all['岗位描述_清洗'] = df_all['岗位描述'].map(lambda x: clean_fn(x) if pd.notna(x) else '')\n",
    "\n",
    "# 输出目录（新建文件夹）\n",
    "base_out_dir = os.path.join('.', '中间文件', 'zhipu_batches')\n",
    "os.makedirs(base_out_dir, exist_ok=True)\n",
    "\n",
    "# 智谱请求体参数\n",
    "system_prompt = (\n",
    "    \"请提取岗位描述信息中的岗位职责或任务，输出{\\\"responsibilities\\\":[\\\"…\\\",\\\"…\\\"]}。\"\n",
    "    \"若岗位描述信息中没有岗位职责，输出{\\\"responsibilities\\\":[]}。\"\n",
    ")\n",
    "\n",
    "# 切分参数：每个文件 50,000 条\n",
    "chunk_size = 50_000\n",
    "n_rows = len(df_all)\n",
    "import math as _math\n",
    "n_chunks = _math.ceil(n_rows / chunk_size) if n_rows > 0 else 0\n",
    "\n",
    "# 进度条\n",
    "use_tqdm = tqdm is not None and n_rows > 0\n",
    "pbar = tqdm(total=n_rows, desc='Writing Zhipu JSONL') if use_tqdm else None\n",
    "\n",
    "# 使用 reset_index 保留原始行号，custom_id 使用原始行号格式化\n",
    "with_index = df_all.reset_index()\n",
    "\n",
    "for chunk_idx in range(n_chunks):\n",
    "    start = chunk_idx * chunk_size\n",
    "    end = min((chunk_idx + 1) * chunk_size, n_rows)\n",
    "    chunk = with_index.iloc[start:end][['index', '岗位描述_清洗']]\n",
    "\n",
    "    out_path = os.path.join(base_out_dir, f'batch_responsibilities_zhipu_{chunk_idx + 1:03d}.jsonl')\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        # 使用 itertuples(name=None) 以获得更快的迭代\n",
    "        for original_idx, user_text in chunk.itertuples(index=False, name=None):\n",
    "            payload = {\n",
    "                \"custom_id\": f\"resp-{int(original_idx):06d}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v4/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"glm-4-flash\",\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_text or ''}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "            if use_tqdm:\n",
    "                pbar.update(1)\n",
    "\n",
    "    # 分片完成提示（即便无 tqdm 也能看到进度）\n",
    "    print(f'写入完成: {out_path}  [{start}-{end})')\n",
    "\n",
    "if use_tqdm and pbar is not None:\n",
    "    pbar.close()\n",
    "\n",
    "print(f'总记录数: {n_rows}, 总文件数: {n_chunks}, 输出目录: {base_out_dir}')\n",
    "\n",
    "# 预览前两个文件的首行\n",
    "import glob as _glob\n",
    "preview_files = sorted(_glob.glob(os.path.join(base_out_dir, '*.jsonl')))[:2]\n",
    "for fp in preview_files:\n",
    "    print('预览:', fp)\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        print(f.readline().rstrip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be97818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='1757250233_171a269149e0484abfa6d5c0c64abe19', bytes=57815255, created_at=1757250233, filename='batch_responsibilities_zhipu_003.jsonl', object='file', purpose='batch', status=None, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "from zai import ZhipuAiClient\n",
    "\n",
    "client = ZhipuAiClient(api_key=\"569c5512417849eca12a693b5dbb562b.RbV8Ms2ChOI2JvAi\")\n",
    "\n",
    "# 上传批处理文件\n",
    "file_object = client.files.create(\n",
    "    file=open(r\"中间文件\\zhipu_batches\\batch_responsibilities_zhipu_003.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "print(file_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9296712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.3.4\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
