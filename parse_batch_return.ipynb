{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 解析 batch_result JSONL 为 DataFrame\n",
        "\n",
        "用途：\n",
        "- 读取 `中间文件/batch_return_files/batch_result_batch_1964900313258266624.jsonl`\n",
        "- 将 JSONL 解析为 Pandas DataFrame（兼容部分不规范行）\n",
        "- 预览数据基本信息\n",
        "\n",
        "运行下方所有代码单元即可得到 `df` 数据集。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSONL path: d:\\BaiduNetdiskDownload\\招聘数据\\merge_listed\\中间文件\\batch_return_files\\batch_result_batch_1964959511140634624.jsonl\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "文件不存在: d:\\BaiduNetdiskDownload\\招聘数据\\merge_listed\\中间文件\\batch_return_files\\batch_result_batch_1964959511140634624.jsonl",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m jsonl_path = project_root / \u001b[33m\"\u001b[39m\u001b[33m中间文件\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mbatch_return_files\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mbatch_result_batch_1964959511140634624.jsonl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJSONL path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjsonl_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m jsonl_path.exists(), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m文件不存在: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjsonl_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_extract_json_substring\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     23\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"在一行文本中提取第一个完整的 { ... } JSON 子串。\"\"\"\u001b[39;00m\n",
            "\u001b[31mAssertionError\u001b[39m: 文件不存在: d:\\BaiduNetdiskDownload\\招聘数据\\merge_listed\\中间文件\\batch_return_files\\batch_result_batch_1964959511140634624.jsonl"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "from json import JSONDecodeError\n",
        "from typing import Any, Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# # 更友好的显示设置\n",
        "# pd.set_option(\"display.max_columns\", 100)\n",
        "# pd.set_option(\"display.width\", 160)\n",
        "# pd.set_option(\"display.max_colwidth\", 200)\n",
        "\n",
        "# # JSONL 文件路径（相对当前工作目录）\n",
        "# project_root = Path.cwd()\n",
        "# jsonl_path = project_root / \"中间文件\" / \"batch_return_files\" / \"batch_result_batch_1964959511140634624.jsonl\"\n",
        "# print(f\"JSONL path: {jsonl_path}\")\n",
        "# assert jsonl_path.exists(), f\"文件不存在: {jsonl_path}\"\n",
        "\n",
        "\n",
        "def _extract_json_substring(text: str) -> str | None:\n",
        "    \"\"\"在一行文本中提取第一个完整的 { ... } JSON 子串。\"\"\"\n",
        "    start = text.find(\"{\")\n",
        "    end = text.rfind(\"}\")\n",
        "    if start != -1 and end != -1 and end > start:\n",
        "        return text[start : end + 1]\n",
        "    return None\n",
        "\n",
        "\n",
        "def parse_json_line(line: str) -> Tuple[Dict[str, Any] | None, str | None]:\n",
        "    \"\"\"尝试将单行 JSONL 文本解析为字典。\n",
        "\n",
        "    返回: (obj, err)\n",
        "      - obj: 解析成功的字典\n",
        "      - err: 解析失败的错误信息字符串\n",
        "    \"\"\"\n",
        "    raw = line.strip()\n",
        "    if not raw:\n",
        "        return None, None\n",
        "\n",
        "    # 常见场景：SSE 或日志前缀，如 \"data: {...}\"\n",
        "    if raw.startswith(\"data:\"):\n",
        "        raw = raw[5:].strip()\n",
        "\n",
        "    # 尝试直接解析\n",
        "    try:\n",
        "        return json.loads(raw), None\n",
        "    except JSONDecodeError as e1:\n",
        "        # 尝试从文本中提取 JSON 子串\n",
        "        candidate = _extract_json_substring(raw)\n",
        "        if candidate:\n",
        "            try:\n",
        "                return json.loads(candidate), None\n",
        "            except JSONDecodeError as e2:\n",
        "                return None, f\"JSONDecodeError after substring extract: {e2} | line sample: {raw[:200]}\"\n",
        "        return None, f\"JSONDecodeError: {e1} | line sample: {raw[:200]}\"\n",
        "\n",
        "\n",
        "def load_jsonl(path: Path) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
        "    \"\"\"逐行解析 JSONL，返回 (records, errors)。\n",
        "\n",
        "    errors: [{line_no, error, line_sample}] 列表\n",
        "    \"\"\"\n",
        "    records: List[Dict[str, Any]] = []\n",
        "    errors: List[Dict[str, Any]] = []\n",
        "\n",
        "    with path.open(\"r\", encoding=\"utf-8-sig\", errors=\"replace\") as f:\n",
        "        for idx, line in enumerate(f, start=1):\n",
        "            obj, err = parse_json_line(line)\n",
        "            if obj is not None:\n",
        "                records.append(obj)\n",
        "            elif err:\n",
        "                errors.append({\n",
        "                    \"line_no\": idx,\n",
        "                    \"error\": err,\n",
        "                })\n",
        "            # 空行则忽略\n",
        "    return records, errors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 77 files in batch_return_files directory\n",
            "Processing file: 中间文件\\batch_return_files\\batch_result_batch_1964897795249676288.jsonl\n"
          ]
        }
      ],
      "source": [
        "# 读取与构建 DataFrame\n",
        "# 读取中间文件\\batch_return_files中的所有文件名称\n",
        "from pathlib import Path\n",
        "\n",
        "batch_return_dir = Path(\"中间文件/batch_return_files\")\n",
        "path_list = []\n",
        "\n",
        "if batch_return_dir.exists() and batch_return_dir.is_dir():\n",
        "    path_list = [f for f in batch_return_dir.iterdir() if f.is_file()]\n",
        "    print(f\"Found {len(path_list)} files in batch_return_files directory\")\n",
        "else:\n",
        "    print(\"batch_return_files directory not found\")\n",
        "\n",
        "# 假设我们要处理第一个文件（如果存在的话）\n",
        "if path_list:\n",
        "    jsonl_path = path_list[0]\n",
        "    print(f\"Processing file: {jsonl_path}\")\n",
        "else:\n",
        "    # 如果没有找到文件，使用默认路径\n",
        "    jsonl_path = Path(\"中间文件/batch_return_files/default.jsonl\")\n",
        "    print(\"No files found, using default path\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files: 100%|██████████| 77/77 [00:53<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parsed records: 3813694 | Total errors: 0\n",
            "(3813694, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>custom_id</th>\n",
              "      <th>id</th>\n",
              "      <th>response.status_code</th>\n",
              "      <th>response.body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>desc-0001308</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>200</td>\n",
              "      <td>{'created': 1757303575, 'usage': {'completion_tokens': 26, 'prompt_tokens': 127, 'total_tokens': 153}, 'model': 'glm-4-flash', 'id': '20250908115254197aa7871f954124', 'choices': [{'finish_reason':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>desc-0001344</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>200</td>\n",
              "      <td>{'created': 1757303577, 'usage': {'completion_tokens': 109, 'prompt_tokens': 279, 'total_tokens': 388}, 'model': 'glm-4-flash', 'id': '20250908115254a5244eb6917b417e', 'choices': [{'finish_reason'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>desc-0001352</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>200</td>\n",
              "      <td>{'created': 1757303575, 'usage': {'completion_tokens': 52, 'prompt_tokens': 192, 'total_tokens': 244}, 'model': 'glm-4-flash', 'id': '2025090811525421f560e491704cd1', 'choices': [{'finish_reason':...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      custom_id                         id  response.status_code  \\\n",
              "0  desc-0001308  batch_1964897795249676288                   200   \n",
              "1  desc-0001344  batch_1964897795249676288                   200   \n",
              "2  desc-0001352  batch_1964897795249676288                   200   \n",
              "\n",
              "                                                                                                                                                                                             response.body  \n",
              "0  {'created': 1757303575, 'usage': {'completion_tokens': 26, 'prompt_tokens': 127, 'total_tokens': 153}, 'model': 'glm-4-flash', 'id': '20250908115254197aa7871f954124', 'choices': [{'finish_reason':...  \n",
              "1  {'created': 1757303577, 'usage': {'completion_tokens': 109, 'prompt_tokens': 279, 'total_tokens': 388}, 'model': 'glm-4-flash', 'id': '20250908115254a5244eb6917b417e', 'choices': [{'finish_reason'...  \n",
              "2  {'created': 1757303575, 'usage': {'completion_tokens': 52, 'prompt_tokens': 192, 'total_tokens': 244}, 'model': 'glm-4-flash', 'id': '2025090811525421f560e491704cd1', 'choices': [{'finish_reason':...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "all_records = []\n",
        "all_errors = []\n",
        "\n",
        "# 循环读取path_list中的所有文件\n",
        "for jsonl_path in tqdm(path_list, desc=\"Processing files\"):\n",
        "    records, errors = load_jsonl(jsonl_path)\n",
        "    \n",
        "    # 合并到总列表中\n",
        "    all_records.extend(records)\n",
        "    all_errors.extend(errors)\n",
        "\n",
        "print(f\"Total parsed records: {len(all_records)} | Total errors: {len(all_errors)}\")\n",
        "\n",
        "df = pd.json_normalize(all_records, max_level=1)\n",
        "print(df.shape)\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing responsibilities for 3813694 rows with status_code==200...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parsing responsibilities: 100%|██████████| 3813694/3813694 [00:10<00:00, 354760.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows with status_code==200: 3813694 | Parsed responsibilities: 3812561\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>custom_id</th>\n",
              "      <th>id</th>\n",
              "      <th>responsibilities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>desc-0001308</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[负责成品的组装、包装, 对组装工艺进行优化, 组装出现问题事汇总]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>desc-0001344</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[负责公司内部局域网维护, 进行交换机、服务器、路由器等设备管理，以及网络平台的运行监控和维护, 负责公司内办公相关设备(电脑、打印机、传真机、考勤机、投影仪等）的维护和保养, 负责病毒的查杀，维护网络系统安全, 处理网络及计算机故障, 负责内部信息系统建设、维护, 负责电话交换机、内部线路的维护，保证畅通，维护电话系统, linux/windows/mac系统常规应用的服务的配置管理等]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>desc-0001352</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[负责董事长的工作日程安排, 组织和安排各类会议，撰写和整理会议纪要, 负责文件的处理与存档等, 处理电话、邮件、传真等各种渠道的信息, 协助完成对外联络事宜]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>desc-0001385</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[负责针对销售和代理商的产品培训, 收集国内外同行业的学术信息, 国内学术会议的协助、筹备与实施, 产品上市后临床试验的跟进、数据监察和回收, 培训学院的工作参与：招生、服务与客户接待, 陪同国外专家进行学术交流]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>desc-0001462</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[收集整理用户需求，完成需求收集、确认需求和需求分析工作，编制《用户需求分析》, 组织需求分析，形成产品需求用例，制作页面原型及编写相关文档，并协助研发人员对需求进行理解, 负责需求跟踪与维护，进行需求变更控制, 跟踪产品发展趋势，保证产品设计优势, 引导设计师完成界面设计，追求UI美感与易用，达到极致体验, 协调技术开发人员，跟踪产品开发进度，完成产品的开发、测试、产品上线等工作]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>desc-0001467</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[为银行持卡客户办理账单分期、卡片升级、客户关怀等业务, 严格执行公司制定的各项业务流程, 提升客户满意度]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>desc-0001516</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>desc-0001549</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[负责对公司计算机硬件、软件系统进行建设及维护, 负责B/S架构下的产品开发工作, 参与系统应用和功能模块的设计与程序开发，单元测试，维护文档的编定, 参与公司重大信息化项目的调研、设计以及二次开发借口的维护和调试]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>desc-0001562</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[负责输配电系统的建设、技术指导、运行管理工作, 负责对电气系统的故障分析和处理工作, 负责电气设备的选型、招投标、采购、安装、调试工作, 对电气系统的运行进行安全评估，制定安全策略, 负责制定电气设备的操作规程和管理制度, 负责输配电系统的设计工作, 负责电气设备故障的处理及日常电气设备的维修保养工作]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>desc-0001591</td>\n",
              "      <td>batch_1964897795249676288</td>\n",
              "      <td>[在部门经理的领导下，管理呼叫中心客服团队, 负责策划、完善呼叫中心实施方案、管理制度、业务标准及流程，根据业务发展的实际情况，调整和完善项目内部的管理流程和规范, 管理呼叫中心客服整体业务运营，合理调配客服坐席资源，监控运营质量，不断提升呼叫中心整体业绩, 跟踪业务流程、系统化和部门间的工作协调，协助优化运营流程，不断提升业务准确度和服务效率，使得整个呼叫中心部门达到高水平的客户满意度,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      custom_id                         id  \\\n",
              "0  desc-0001308  batch_1964897795249676288   \n",
              "1  desc-0001344  batch_1964897795249676288   \n",
              "2  desc-0001352  batch_1964897795249676288   \n",
              "3  desc-0001385  batch_1964897795249676288   \n",
              "4  desc-0001462  batch_1964897795249676288   \n",
              "5  desc-0001467  batch_1964897795249676288   \n",
              "6  desc-0001516  batch_1964897795249676288   \n",
              "7  desc-0001549  batch_1964897795249676288   \n",
              "8  desc-0001562  batch_1964897795249676288   \n",
              "9  desc-0001591  batch_1964897795249676288   \n",
              "\n",
              "                                                                                                                                                                                          responsibilities  \n",
              "0                                                                                                                                                                       [负责成品的组装、包装, 对组装工艺进行优化, 组装出现问题事汇总]  \n",
              "1     [负责公司内部局域网维护, 进行交换机、服务器、路由器等设备管理，以及网络平台的运行监控和维护, 负责公司内办公相关设备(电脑、打印机、传真机、考勤机、投影仪等）的维护和保养, 负责病毒的查杀，维护网络系统安全, 处理网络及计算机故障, 负责内部信息系统建设、维护, 负责电话交换机、内部线路的维护，保证畅通，维护电话系统, linux/windows/mac系统常规应用的服务的配置管理等]  \n",
              "2                                                                                                                         [负责董事长的工作日程安排, 组织和安排各类会议，撰写和整理会议纪要, 负责文件的处理与存档等, 处理电话、邮件、传真等各种渠道的信息, 协助完成对外联络事宜]  \n",
              "3                                                                                              [负责针对销售和代理商的产品培训, 收集国内外同行业的学术信息, 国内学术会议的协助、筹备与实施, 产品上市后临床试验的跟进、数据监察和回收, 培训学院的工作参与：招生、服务与客户接待, 陪同国外专家进行学术交流]  \n",
              "4        [收集整理用户需求，完成需求收集、确认需求和需求分析工作，编制《用户需求分析》, 组织需求分析，形成产品需求用例，制作页面原型及编写相关文档，并协助研发人员对需求进行理解, 负责需求跟踪与维护，进行需求变更控制, 跟踪产品发展趋势，保证产品设计优势, 引导设计师完成界面设计，追求UI美感与易用，达到极致体验, 协调技术开发人员，跟踪产品开发进度，完成产品的开发、测试、产品上线等工作]  \n",
              "5                                                                                                                                                   [为银行持卡客户办理账单分期、卡片升级、客户关怀等业务, 严格执行公司制定的各项业务流程, 提升客户满意度]  \n",
              "6                                                                                                                                                                                                       []  \n",
              "7                                                                                             [负责对公司计算机硬件、软件系统进行建设及维护, 负责B/S架构下的产品开发工作, 参与系统应用和功能模块的设计与程序开发，单元测试，维护文档的编定, 参与公司重大信息化项目的调研、设计以及二次开发借口的维护和调试]  \n",
              "8                                                [负责输配电系统的建设、技术指导、运行管理工作, 负责对电气系统的故障分析和处理工作, 负责电气设备的选型、招投标、采购、安装、调试工作, 对电气系统的运行进行安全评估，制定安全策略, 负责制定电气设备的操作规程和管理制度, 负责输配电系统的设计工作, 负责电气设备故障的处理及日常电气设备的维修保养工作]  \n",
              "9  [在部门经理的领导下，管理呼叫中心客服团队, 负责策划、完善呼叫中心实施方案、管理制度、业务标准及流程，根据业务发展的实际情况，调整和完善项目内部的管理流程和规范, 管理呼叫中心客服整体业务运营，合理调配客服坐席资源，监控运营质量，不断提升呼叫中心整体业绩, 跟踪业务流程、系统化和部门间的工作协调，协助优化运营流程，不断提升业务准确度和服务效率，使得整个呼叫中心部门达到高水平的客户满意度,...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 解析大模型输出为 Python 列表列 `responsibilities`\n",
        "from typing import Any, Dict, List, Tuple\n",
        "from json_repair import repair_json\n",
        "from tqdm import tqdm\n",
        "# json_repair 安装与导入（若不可用则跳过）\n",
        "\n",
        "\n",
        "\n",
        "def parse_content_to_responsibilities(content: Any) -> Tuple[List[str] | None, str | None]:\n",
        "    if content is None:\n",
        "        return None, \"no_content\"\n",
        "\n",
        "    # 如果已经是 dict，直接从字段中取\n",
        "    if isinstance(content, dict):\n",
        "        if \"responsibilities\" in content and isinstance(content[\"responsibilities\"], list):\n",
        "            items = [str(x).strip() for x in content[\"responsibilities\"]]\n",
        "            items = [x for x in items if x]\n",
        "            return items, None\n",
        "        # 有些模型会嵌套 content 字段\n",
        "        if \"content\" in content:\n",
        "            return parse_content_to_responsibilities(content[\"content\"])\n",
        "        return None, \"dict_without_responsibilities\"\n",
        "\n",
        "    # 如果是字符串，通常是一个 JSON 字符串，先尝试 json.loads\n",
        "    if isinstance(content, str):\n",
        "        s = content.strip()\n",
        "        try:\n",
        "            loaded = json.loads(s)\n",
        "        except Exception as e1:\n",
        "            # 先尝试从字符串中提取 {...} 子串\n",
        "            candidate = _extract_json_substring(s)\n",
        "            # 1) 直接解析子串\n",
        "            if candidate:\n",
        "                try:\n",
        "                    loaded = json.loads(candidate)\n",
        "                except Exception:\n",
        "                    loaded = None\n",
        "            else:\n",
        "                loaded = None\n",
        "\n",
        "            # 2) 如果仍失败并且可用，尝试 json_repair 修复（对子串优先）\n",
        "            if loaded is None:\n",
        "                try:\n",
        "                    to_repair = candidate if candidate else s\n",
        "                    if repair_json is None:\n",
        "                        raise RuntimeError(\"json_repair_not_available\")\n",
        "                    repaired = repair_json(to_repair)\n",
        "                    loaded = json.loads(repaired)\n",
        "                except Exception as e_repair:\n",
        "                    return None, f\"json_repair_failed:{e_repair}\"\n",
        "        return parse_content_to_responsibilities(loaded)\n",
        "\n",
        "    return None, f\"unsupported_content_type:{type(content).__name__}\"\n",
        "\n",
        "\n",
        "def parse_responsibilities_from_body(body: Any) -> Tuple[List[str] | None, str | None]:\n",
        "    if not isinstance(body, dict):\n",
        "        return None, \"body_not_dict\"\n",
        "\n",
        "    # 优先从 choices[0].message.content 提取\n",
        "    content = None\n",
        "    choices = body.get(\"choices\")\n",
        "    if isinstance(choices, list) and len(choices) > 0 and isinstance(choices[0], dict):\n",
        "        first = choices[0]\n",
        "        msg = first.get(\"message\")\n",
        "        if isinstance(msg, dict):\n",
        "            content = msg.get(\"content\")\n",
        "        if content is None:\n",
        "            content = first.get(\"content\")\n",
        "        if content is None and isinstance(first.get(\"delta\"), dict):\n",
        "            content = first[\"delta\"].get(\"content\")\n",
        "\n",
        "    # 其他可能位置\n",
        "    if content is None:\n",
        "        message_field = body.get(\"message\") if isinstance(body.get(\"message\"), dict) else {}\n",
        "        content = (\n",
        "            body.get(\"output_text\")\n",
        "            or body.get(\"content\")\n",
        "            or (message_field.get(\"content\") if isinstance(message_field, dict) else None)\n",
        "        )\n",
        "\n",
        "    return parse_content_to_responsibilities(content)\n",
        "\n",
        "\n",
        "# 仅解析 status_code == 200 的行\n",
        "mask_ok = df[\"response.status_code\"] == 200\n",
        "print(f\"Parsing responsibilities for {mask_ok.sum()} rows with status_code==200...\")\n",
        "\n",
        "# 使用 tqdm 添加进度条\n",
        "tqdm.pandas(desc=\"Parsing responsibilities\")\n",
        "parsed_series = df.loc[mask_ok, \"response.body\"].progress_apply(parse_responsibilities_from_body)\n",
        "\n",
        "df.loc[mask_ok, \"responsibilities\"] = parsed_series.map(lambda t: t[0])\n",
        "df.loc[mask_ok, \"responsibilities_error\"] = parsed_series.map(lambda t: t[1])\n",
        "\n",
        "# 统计与预览\n",
        "num_ok = int(mask_ok.sum())\n",
        "# num_parsed = int(df.loc[mask_ok, \"responsibilities\"].apply(lambda x: isinstance(x, list) and len(x) > 0).sum())\n",
        "num_parsed = int(df.loc[mask_ok, \"responsibilities\"].apply(lambda x: isinstance(x, list)).sum())\n",
        "print(f\"Rows with status_code==200: {num_ok} | Parsed responsibilities: {num_parsed}\")\n",
        "\n",
        "cols = [c for c in [\"custom_id\", \"id\", \"responsibilities\"] if c in df.columns]\n",
        "df[cols].head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = df[[\"custom_id\", \"id\", \"responsibilities\",'responsibilities_error']]\n",
        "output = output[output['responsibilities_error'].isna()]\n",
        "output = output[output['responsibilities'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n",
        "# 对responsibilities列中的列表进行去重处理\n",
        "output['responsibilities'] = output['responsibilities'].apply(lambda x: list(dict.fromkeys(x)) if isinstance(x, list) else x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "总错误数量: 1133\n",
            "错误类型数量: 5\n",
            "\n",
            "各类错误统计:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "responsibilities_error\n",
              "json_repair_failed:Expecting value: line 1 column 1 (char 0)    758\n",
              "unsupported_content_type:list                                   343\n",
              "dict_without_responsibilities                                    30\n",
              "json_repair_failed:maximum recursion depth exceeded               1\n",
              "json_repair_failed:string index out of range                      1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 统计错误数量\n",
        "error_counts = df['responsibilities_error'].value_counts()\n",
        "print(f\"总错误数量: {error_counts.sum()}\")\n",
        "print(f\"错误类型数量: {len(error_counts)}\")\n",
        "print(\"\\n各类错误统计:\")\n",
        "error_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "output['len'] = output['responsibilities'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "len\n",
              "1       98635\n",
              "2      190189\n",
              "3      492816\n",
              "4      714133\n",
              "5      703666\n",
              "        ...  \n",
              "92          2\n",
              "103         1\n",
              "111         1\n",
              "117         1\n",
              "136         1\n",
              "Name: count, Length: 86, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output['len'].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "output[1500000:][['responsibilities']].to_parquet('list_par2.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7704638"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(output[:1500000]['responsibilities'].explode().to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可选：导出结果\n",
        "out_dir = project_root / \"中间文件\" / \"batch_return_files\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "csv_path = out_dir / \"batch_result_batch_1964900313258266624.parsed.csv\"\n",
        "parquet_path = out_dir / \"batch_result_batch_1964900313258266624.parsed.parquet\"\n",
        "\n",
        "print(f\"Writing CSV -> {csv_path}\")\n",
        "df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"Writing Parquet -> {parquet_path}\")\n",
        "df.to_parquet(parquet_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 批量解析并合并 `中间文件/batch_return_files` 下的所有 JSONL\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from tqdm import tqdm\n",
        "\n",
        "jsonl_dir = project_root / \"中间文件\" / \"batch_return_files\"\n",
        "all_jsonl_files: List[Path] = sorted(jsonl_dir.glob(\"*.jsonl\"))\n",
        "print(f\"Found {len(all_jsonl_files)} JSONL files under {jsonl_dir}\")\n",
        "\n",
        "\n",
        "def process_one_jsonl(path: Path) -> pd.DataFrame:\n",
        "    records, errors = load_jsonl(path)\n",
        "    if not records:\n",
        "        df_empty = pd.DataFrame({\n",
        "            \"file\": [path.name],\n",
        "            \"parse_exception\": [None],\n",
        "        })\n",
        "        return df_empty\n",
        "\n",
        "    df_one = pd.json_normalize(records, max_level=1)\n",
        "\n",
        "    # 尝试解析 responsibilities\n",
        "    if \"response.body\" in df_one.columns:\n",
        "        parsed_series = df_one[\"response.body\"].apply(parse_responsibilities_from_body)\n",
        "        df_one[\"responsibilities\"] = parsed_series.map(lambda t: t[0])\n",
        "        df_one[\"responsibilities_error\"] = parsed_series.map(lambda t: t[1])\n",
        "\n",
        "    df_one[\"file\"] = path.name\n",
        "\n",
        "    keep_cols = [\n",
        "        c for c in [\n",
        "            \"custom_id\",\n",
        "            \"id\",\n",
        "            \"response.status_code\",\n",
        "            \"responsibilities\",\n",
        "            \"responsibilities_error\",\n",
        "            \"file\",\n",
        "        ] if c in df_one.columns\n",
        "    ]\n",
        "    return df_one[keep_cols]\n",
        "\n",
        "\n",
        "batch_frames: List[pd.DataFrame] = []\n",
        "for p in tqdm(all_jsonl_files, desc=\"Parsing JSONL files\"):\n",
        "    try:\n",
        "        batch_frames.append(process_one_jsonl(p))\n",
        "    except Exception as e:\n",
        "        batch_frames.append(pd.DataFrame({\n",
        "            \"file\": [p.name],\n",
        "            \"parse_exception\": [str(e)],\n",
        "        }))\n",
        "\n",
        "merged_all = pd.concat(batch_frames, ignore_index=True, sort=False) if batch_frames else pd.DataFrame()\n",
        "print(\"Merged shape:\", merged_all.shape)\n",
        "\n",
        "num_rows = len(merged_all)\n",
        "num_resp = int(merged_all.get(\"responsibilities\", pd.Series(dtype=object)).apply(lambda x: isinstance(x, list)).sum()) if not merged_all.empty else 0\n",
        "print(f\"Total rows: {num_rows} | Rows with parsed responsibilities (is list): {num_resp}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 去重、筛选与导出\n",
        "import math\n",
        "\n",
        "if 'merged_all' not in globals():\n",
        "    raise RuntimeError(\"merged_all 未定义，请先运行上一个合并单元格。\")\n",
        "\n",
        "if merged_all.empty:\n",
        "    print(\"merged_all is empty; nothing to export.\")\n",
        "else:\n",
        "    dfm = merged_all.copy()\n",
        "\n",
        "    # 判定 responsibilities 是否为非空列表\n",
        "    def _is_non_empty_list(x):\n",
        "        return isinstance(x, list) and len(x) > 0\n",
        "\n",
        "    dfm['is_list'] = dfm.get('responsibilities', pd.Series([None]*len(dfm))).apply(_is_non_empty_list)\n",
        "    dfm['len_list'] = dfm.get('responsibilities', pd.Series([None]*len(dfm))).apply(lambda x: len(x) if isinstance(x, list) else -1)\n",
        "\n",
        "    # 选主键列\n",
        "    key_col = 'custom_id' if 'custom_id' in dfm.columns else ('id' if 'id' in dfm.columns else None)\n",
        "    if key_col is None:\n",
        "        key_col = '_row_index'\n",
        "        dfm[key_col] = dfm.index.astype(str)\n",
        "\n",
        "    # 标记 200 OK\n",
        "    status = dfm.get('response.status_code', pd.Series([-1]*len(dfm)))\n",
        "    dfm['_is_ok'] = status.eq(200)\n",
        "\n",
        "    # 排序：优先 200 且 responsibilities 更长\n",
        "    dfm_sorted = dfm.sort_values(by=['_is_ok', 'is_list', 'len_list'], ascending=[False, False, False])\n",
        "\n",
        "    # 去重保留最佳行\n",
        "    best_rows = dfm_sorted.drop_duplicates(subset=[key_col], keep='first').copy()\n",
        "\n",
        "    # 导出两份：\n",
        "    # 1) 仅保留解析出 responsibilities 的记录\n",
        "    parsed = best_rows[best_rows['is_list']].copy()\n",
        "\n",
        "    # 2) 全量最佳（含未解析者），便于排错\n",
        "    best_all = best_rows.copy()\n",
        "\n",
        "    # 选择导出列（存在则导出）\n",
        "    export_cols = [c for c in [key_col, 'custom_id', 'id', 'responsibilities', 'responsibilities_error', 'response.status_code', 'file'] if c in best_rows.columns]\n",
        "\n",
        "    out_dir = project_root / '中间文件'\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    out_parsed_csv = out_dir / 'batch_return_merged.csv'\n",
        "    out_parsed_parquet = out_dir / 'batch_return_merged.parquet'\n",
        "    out_best_all_parquet = out_dir / 'batch_return_merged_all.parquet'\n",
        "\n",
        "    print(f\"Saving parsed-only CSV -> {out_parsed_csv}\")\n",
        "    parsed[export_cols].to_csv(out_parsed_csv, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"Saving parsed-only Parquet -> {out_parsed_parquet}\")\n",
        "    parsed[export_cols].to_parquet(out_parsed_parquet, index=False)\n",
        "\n",
        "    print(f\"Saving best-all Parquet -> {out_best_all_parquet}\")\n",
        "    best_all[export_cols].to_parquet(out_best_all_parquet, index=False)\n",
        "\n",
        "    print(\n",
        "        f\"Done. parsed-only rows: {len(parsed)} / best-all rows: {len(best_all)} | key_col: {key_col}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_parquet('list_par_with_matches.parquet')\n",
        "df2 = pd.read_parquet('list_par2_with_matches.parquet')\n",
        "dfx = pd.concat([df1,df2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = output.reset_index(drop=True)\n",
        "dfx = dfx.reset_index(drop=True)\n",
        "output.drop('responsibilities',inplace=True,axis =1)\n",
        "merged = pd.concat([output,dfx],axis = 1)\n",
        "merged = merged[['custom_id', 'responsibilities', 'responsibilities_match']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.to_parquet('id_responsibility_match.parquet')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
